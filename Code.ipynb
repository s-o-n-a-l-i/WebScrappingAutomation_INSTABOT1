{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><u><b>Project InstaBot Part 1 </h1></u></b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> InstaBot Introduction - Part 1</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your friend has opened a new Food Blogging handle on Instagram and wants to get famous. \n",
    "He wants to follow a lot of people so that he can get noticed quickly but it is a tedious \n",
    "task so he asks you to help him. As you have just learned automation using Selenium, you decided to \n",
    "help him by creating an Instagram Bot.<br>\n",
    "You need to create different functions for each task.<br>\n",
    "<b>Note :</b>\n",
    "Don’t forget to remove your Username and Password from the python notebook before submission.<br>\n",
    "Replace your username and password by ‘SAMPLE USERNAME’ and ‘SAMPLE PASSWORD’ where you have used them in your code for logging in to instagram<br>\n",
    "Upload your code file for submission of this project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> InstaBot - Part 1</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>ASK 1</h2>\n",
    "<b><h4>Login to your Instagram Handle</b></h4>\n",
    "Note: Submit with sample username and password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets first of all import the required web driver library from selenium package\n",
    "# Also lets initiate web browser driver\n",
    "\n",
    "from selenium import webdriver\n",
    "driver = webdriver.Chrome(executable_path = r'C:\\Users\\vigya\\PycharmProjects\\Temp1Learn\\chromedriver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we'll make a URL visit request after visiting lets also maximize window\n",
    "\n",
    "driver.get(\"https://www.instagram.com/\")\n",
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After inspecting we found username input box has attribute username\n",
    "# using which we will locate the particular textbox and send values to it\n",
    "\n",
    "usernamebutton = driver.find_element_by_name(\"username\")\n",
    "usernamebutton.send_keys(\"SAMPLE USERNAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After again inspecting we found Password input box has attribute password\n",
    "# using which we will locate the particular textbox and send values to it\n",
    "# Also we will use the submit as it has type submit\n",
    "\n",
    "passwordbutton = driver.find_element_by_name(\"password\")\n",
    "passwordbutton.send_keys(\"SAMPLE PASSWORD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "passwordbutton.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now there will be an ask to save info or not \n",
    "# so we will not save info currently\n",
    "# some time this ask doesnt appear on some computer to save info so please consider if it appears \n",
    "\n",
    "saveinfo_notnow = driver.find_element_by_class_name(\"cmbtv\")\n",
    "saveinfo_notnow.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A \"Turn on notification\" pop up appears which need to be dismissed\"\n",
    "# so we will locate the element by provided class name in html data and click over it\n",
    "\n",
    "notifypopup_dismiss = driver.find_element_by_class_name(\"mt3GC\")\n",
    "notifypopup_dismiss.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>ASK 2</h2>\n",
    "<b><h4>Type for “food” in search bar and print all the names of the Instagram Handles that are displayed in list after typing “food”</b></h4>\n",
    "Note: Make sure to avoid printing hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First thing we will do is we will locate the search bar text box and then send value to the particular box\n",
    "\n",
    "searchbutton = driver.find_element_by_class_name(\"XTCLo\")\n",
    "searchbutton.send_keys(\"food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Over here in textbox we need not to click on the search bar html data is already refreshed as soon we typed in bar\n",
    "# Also if we try to press enter after writing into the textbox nothing happens\n",
    "# if needed to press ENTER we could have done this as below \n",
    "# But as its not needed lets comment it out\n",
    "\n",
    "# from selenium.webdriver.common.keys import Keys\n",
    "# searchbutton.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<div class=\"_7UhW9 PIoXz qyrsm uL8Hv\">Switch</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm _0PwGv uL8Hv\">Suggestions For You</div>,\n",
       " <div class=\"_7UhW9 PIoXz qyrsm KV-D4 uL8Hv\">See All</div>,\n",
       " <div class=\"_7UhW9 PIoXz qyrsm uL8Hv\">Follow</div>,\n",
       " <div class=\"_7UhW9 PIoXz qyrsm uL8Hv\">Follow</div>,\n",
       " <div class=\"_7UhW9 PIoXz qyrsm uL8Hv\">Follow</div>,\n",
       " <div class=\"_7UhW9 PIoXz qyrsm uL8Hv\">Follow</div>,\n",
       " <div class=\"_7UhW9 PIoXz qyrsm uL8Hv\">Follow</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">foodymonkcafe</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">the.food_cult</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">delhi_street_food1</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">foodtalkindia</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">foodie_incarnate</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">#food</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">delhifoodwalks</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">food</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">dilsefoodie</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">fastfoody.mumbai</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">yourfoodlab</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">delhi_streets_food</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">mumbaifoodie</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">food.babyy_</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">#foodporn</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">foodporn</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">#foodie</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">delhiicious</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">foodwidfatties</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">thisisdelhi</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">foodnetwork</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">foodinsider</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">_indian.foodie_</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">#foodblogger</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">foodiee_says</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">foodiesafarii</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">food_junc</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">foodholic.delhi</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">food.darzee</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">food.o.holic</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">foodiesince96</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">food_bunny98</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">food52</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">food_mad101</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">#foodphotography</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">food_n_cafe</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">food_bae_lover</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">foodie_chandni</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">delhifoodnest</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">food_maple05</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">delhifoodgirl</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">food_tech_govind</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">foodchrome</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">delhifoodsandco</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">foodvoodindia</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">food_food_delhi</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">Food Street</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">bhukkhadbybirth</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">delhitimes.food</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">foodpremi_</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">bcuz_itz_food</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">food.hangover_</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">thefood.vlogger</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">Food Junction Grand Pakuwon</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">eatlikeamaniac</div>,\n",
       " <div class=\"_7UhW9 xLCgt qyrsm KV-D4 uL8Hv\">#foodstylist</div>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As we have sent the value to textbox now only need is to extract the info by BeautifulSoup\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "data = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "names = data.find_all(class_ = \"qyrsm\")\n",
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foodymonkcafe\n",
      "the.food_cult\n",
      "delhi_street_food1\n",
      "foodtalkindia\n",
      "foodie_incarnate\n",
      "delhifoodwalks\n",
      "food\n",
      "dilsefoodie\n",
      "fastfoody.mumbai\n",
      "yourfoodlab\n",
      "delhi_streets_food\n",
      "mumbaifoodie\n",
      "food.babyy_\n",
      "foodporn\n",
      "delhiicious\n",
      "foodwidfatties\n",
      "thisisdelhi\n",
      "foodnetwork\n",
      "foodinsider\n",
      "_indian.foodie_\n",
      "foodiee_says\n",
      "foodiesafarii\n",
      "food_junc\n",
      "foodholic.delhi\n",
      "food.darzee\n",
      "food.o.holic\n",
      "foodiesince96\n",
      "food_bunny98\n",
      "food52\n",
      "food_mad101\n",
      "food_n_cafe\n",
      "food_bae_lover\n",
      "foodie_chandni\n",
      "delhifoodnest\n",
      "food_maple05\n",
      "delhifoodgirl\n",
      "food_tech_govind\n",
      "foodchrome\n",
      "delhifoodsandco\n",
      "foodvoodindia\n",
      "food_food_delhi\n",
      "Food Street\n",
      "bhukkhadbybirth\n",
      "delhitimes.food\n",
      "foodpremi_\n",
      "bcuz_itz_food\n",
      "food.hangover_\n",
      "thefood.vlogger\n",
      "Food Junction Grand Pakuwon\n",
      "eatlikeamaniac\n"
     ]
    }
   ],
   "source": [
    "# To deselect the 1st string i.e \"sujjestions for you\" and others , Hashtags\n",
    "# we can run a loop from 8 and include a condition to pass iteration if 1st element of string is \"#\"\n",
    "\n",
    "for i in range(8,len(names)):\n",
    "    st = names[i].string\n",
    "    if st[0] == \"#\":\n",
    "        pass\n",
    "    else:\n",
    "        print(st)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>ASK 3</h2>\n",
    "<b><h4>Searching and Opening a profile using </b></h4>\n",
    "Note: Open profile of “So Delhi” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As earlier we typed food in the searchbar text box we need to clear the particular text \n",
    "# For which we need to find the clear button element location and click over it\n",
    "\n",
    "clearbutton = driver.find_element_by_class_name(\"aIYm8\")\n",
    "clearbutton.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we will locate the search bar text box and then send value \"So Delhi\" to the particular box\n",
    "\n",
    "searchbutton = driver.find_element_by_class_name(\"XTCLo\")\n",
    "searchbutton.send_keys(\"So Delhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will locate the So delhi in sujjestions that we get after sending values to search bar\n",
    "# Ofcourse so delhi would be on top of the list as we typed the same handel , so we will just click on the first one.\n",
    "\n",
    "sodelhi_button = driver.find_element_by_class_name(\"-qQT3\")\n",
    "sodelhi_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>ASK 4</h2><br>\n",
    "<b><h4>Follow/Unfollow given handle - </b></h4>\n",
    "<b>Task1:</b><br>\n",
    "Open the Instagram Handle of “So Delhi”<br>\n",
    "<b>Task2:</b><br>\n",
    "Start following it. Print a message if you are already following<br>\n",
    "<b>Task3:</b><br>\n",
    "After following, unfollow the instagram handle. Print a message if you have already unfollowed<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we see Task 1 has already been done\n",
    "# focusing towards task 2 i.e to follow it . also we will print a message if we already follow it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task2:</b><br>Start following it. Print a message if you are already following<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handle Just Followed\n"
     ]
    }
   ],
   "source": [
    "# We will check for message button that appears only after we follow a handle \n",
    "# if the message button is present it will not throw any error and will print \"Handle Already Followed\"\n",
    "# But if it is not present it will throw exception \n",
    "# and in except block we will write code to follow the handle\n",
    "\n",
    "try:\n",
    "    driver.find_element_by_class_name(\"_8A5w5\")\n",
    "    print(\"Handle Already Followed\")\n",
    "except:\n",
    "    follow_button = driver.find_element_by_class_name(\"_5f5mN\")\n",
    "    follow_button.click()\n",
    "    print(\"Handle Just Followed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Task3:</b><br>After following, unfollow the instagram handle. Print a message if you have already unfollowed<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Handle Just Unfollowed\n"
     ]
    }
   ],
   "source": [
    "# We will check for message button that appears only after we follow a handle \n",
    "# if the message button is present it will not throw any exception and we will unfollow the page handle\n",
    "# But if it is not present it will throw exception \n",
    "# and in except block we will write that its already unfollowed\n",
    "\n",
    "try:\n",
    "    driver.find_element_by_class_name(\"_8A5w5\")\n",
    "    follow_button = driver.find_element_by_class_name(\"_5f5mN\")\n",
    "    follow_button.click()\n",
    "    unfollow_button = driver.find_element_by_class_name(\"aOOlW\")\n",
    "    unfollow_button.click()\n",
    "    print(\"Handle Just Unfollowed\")\n",
    "except:\n",
    "    print(\"Handle Already Unfollowed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>ASK 5</h2>\n",
    "<b><h4>Like/Unlike posts</b></h4>\n",
    "<b>Task1:</b><br>\n",
    "Liking the top 30 posts of the ‘dilsefoodie'. Print message if you have already liked it.<br>\n",
    "<b>Task2:</b><br>\n",
    "Unliking the top 30 posts of the ‘dilsefoodie’. Print message if you have already unliked it.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First thing we will do is we will locate the search bar text box and then send value to the particular box\n",
    "\n",
    "searchbutton = driver.find_element_by_class_name(\"XTCLo\")\n",
    "searchbutton.send_keys(\"dilsefoodie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will click over the dilsefoodie page \n",
    "\n",
    "dilsefoodie_button = driver.find_element_by_class_name(\"-qQT3\")\n",
    "dilsefoodie_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use infinite scroll but as this handle has alot of posts and we require only 30 posts its not nessasary\n",
    "\n",
    "# import time\n",
    "# current_height = driver.execute_script('return document.body.scrollHeight;')\n",
    "# while True:\n",
    "#     driver.execute_script('window.scrollTo(0,arguments[0]);',current_height)\n",
    "#     time.sleep(3)\n",
    "#     new_height = driver.execute_script('return document.body.scrollHeight;')\n",
    "#     if new_height == current_height:\n",
    "#         break\n",
    "#     current_height = new_height\n",
    "\n",
    "\n",
    "\n",
    "# We can use below scroll only :- \n",
    "\n",
    "driver.execute_script('window.scrollBy(0,9999);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will make a list of all posts web element after the scross has been done\n",
    "# So that later on we can click over it one by one iterating over the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "postsElement_List = driver.find_elements_by_class_name(\"_9AhH0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(postsElement_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As openig every post and liking it correspondingly needs some wait in between\n",
    "# We would use explicit wait in between each post opening and then liking it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "wait = WebDriverWait(driver,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a list of posts web elements \n",
    "# But as we need to like only first 30 posts we would run the loop for 30 itertations\n",
    "# then we will include wait untill presence of like button appears\n",
    "# after that we will check if its already liked by checking \"Unlike\" in inner HTML of like button web element\n",
    "# if already liked we will print the same\n",
    "# else we will click the like button\n",
    "# after all been done we will cross the post opened and proceed to next post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post 4 has been Already Liked <3\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    postsElement_List = driver.find_elements_by_class_name(\"_9AhH0\")\n",
    "    postsElement_List[i].click()\n",
    "    wait_thenlikebutton_check = wait.until(EC.presence_of_element_located((By.XPATH, '//div[@class = \"QBdPU \"]/span')))\n",
    "    temp = wait_thenlikebutton_check.get_attribute('innerHTML')\n",
    "    if \"Unlike\" in temp:\n",
    "        print(\"Post \"+str(i + 1)+\" has been Already Liked <3\")\n",
    "    else:\n",
    "        like_button = driver.find_element_by_class_name(\"fr66n\")\n",
    "        like_button.click()\n",
    "    cross_button = driver.find_element_by_class_name(\"yiMZG\")\n",
    "    cross_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We already have a list of posts web elements \n",
    "# But as we need to Unlike only first 30 posts that we just liked we would run the loop for 30 itertations only\n",
    "# then we will include wait untill presence of like button appears\n",
    "# after that we will check if its already Unliked by checking \"Like\" in inner HTML of like button web element\n",
    "# if already Unliked we will print the same\n",
    "# else we will click the like button to make it unlike\n",
    "# after all been done we will cross the post opened and proceed to next post\n",
    "# And to escape StaleElementReferenceException we have again located postelementlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post 1 has been Already Unliked </3\n"
     ]
    }
   ],
   "source": [
    "for i in range(30):\n",
    "    postsElement_List = driver.find_elements_by_class_name(\"_9AhH0\")\n",
    "    postsElement_List[i].click()\n",
    "    wait_thenlikebutton_check = wait.until(EC.presence_of_element_located((By.XPATH, '//div[@class = \"QBdPU \"]/span')))\n",
    "    temp = wait_thenlikebutton_check.get_attribute('innerHTML')\n",
    "    if \"Like\" in temp:\n",
    "        print(\"Post \"+str(i + 1)+\" has been Already Unliked </3\")\n",
    "    else:\n",
    "        Unlike_button = driver.find_element_by_class_name(\"fr66n\")\n",
    "        Unlike_button.click()\n",
    "    cross_button = driver.find_element_by_class_name(\"yiMZG\")\n",
    "    cross_button.click()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>ASK 6</h2>\n",
    "<b><h4>Extract list of followers</b></h4>\n",
    "<b>Task1:</b><br>\n",
    "Extract the usernames of the first 500 followers of ‘foodtalkindia’ and ‘sodelhi’.<br>\n",
    "<b>Task2:</b><br>\n",
    "Now print all the followers of “foodtalkindia” that you are following but those who don’t follow you.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> first 500 followers of ‘foodtalkindia’ </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will locate the search bar text box and then send value to the particular box\n",
    "\n",
    "searchbutton = driver.find_element_by_class_name(\"XTCLo\")\n",
    "searchbutton.send_keys(\"foodtalkindia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after that we will click the first page that appear after we have searched for the value\n",
    "\n",
    "foodtalkindia_button = driver.find_element_by_class_name(\"-qQT3\")\n",
    "foodtalkindia_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will locate the follower button by inspecting and then we ll be clicking over the particulaer element\n",
    "\n",
    "followers_button = driver.find_element_by_xpath('//ul[@class = \"k9GMp \"]/li[2]/a')\n",
    "followers_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will take an empty final list in which we will appened the 500 usernames \n",
    "# also we will scroll until the followername list is more than or equal to 500\n",
    "\n",
    "# firstlty we will locate followers window element\n",
    "# start an infinite loop\n",
    "# Scroll on followers window ,not on main window \n",
    "# after each scroll \n",
    "# we will take followers list in every iteration of the scroll then updation it in next iteration \n",
    "# by the new height followers\n",
    "# Once it reaches >= 500 we will break the infinite loop\n",
    "\n",
    "# Lastly we will run over the followers list again and out of the list that must be around 500 usernames\n",
    "# we will run a loop for 500 iteration and take first 500 usernames into final list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['iinfinitystories', 'debnath.chandan.yy21', 'lostsoul6171', 'ppl_call_me_shreyu', 'amraramjuiya98', 'snillburger', 'protagonist_112', 'chul4bul1', 'nikikanani_', 'mohd_aman_23', 'drishyakhannaa', 'manavrew', 'dhruvbaijnath', 'deepak2820gupta', '04_shivangi_09', '___deepak___.58', 'shraddhawakhare', 'dollysinghinsta', 'itz_shruti_v', 'k.t_saurabh14', 'silom_delhi', '_____itz_____balvir', 'talat9412', 'iamparamita_', 'x_anrthi_x', 'paw__dorable', 'pulkit.malikk', 'coastalreef', 'theawkwardladka', 'hii_i_am_viki', 'winkyourlash', 'ruchika_1984', 'anita_borad', 'cakestoriesbykalikee', 'miss_sonu_127', 'sahilk2663', 'harisma_v', 'abhisekmodakrudra', 'lazypotato198', 'hardikraval1106gmail.com2', 'oliva.dx', 'dk_alone_rider_.5464', 'cha.tterjee48', 'm_r_kalyan_', 's_k_singh_patel', 'arr_gupta', '_rajhimself', 'inderjeetkaur576', 'dark._.queen.___', 'sevi.sevi.923724', 'juneandmaca', '_dare_to_sky_', 'tejaswini_rao_athkar', 'tnt_bkc_', 'shilmuscat', 'worldofmeandbeyond', 'perfect_recipe_marathi', 'oye_badmash', 'dandeli_tourism_since_2002', 'the_food_kaleidoscope', 'cour_sim_', 'moneynotepad', 'prayashu_senapaty', 'neetu_04', '_imrahulverma', 'unique_girl2004169', 'cute_girl_radhika_454', 'food_picked', 'ronak_parasher', 'rajkot_food', 'semblancer', 'shraddhaseth', 'ashishshaw86', 'prasen_9246', '2004piyushranjan', '_the_classic_kitchen_', 'suhana_swati', 'insta____q_u_e_e_n', 'duneofneptune', 'nishajaikeshmathur', 'moodyasfoody_', 'karan_202145', 'vishal.dangi.94801116', 'zoyaspbru', 'stephny2020', 'foodons_india', 'rohankumar334', 'rudrabhairav', 'ritiqaparab_', 'previewhomes', 'niladrighosh253', 'abinav_shrikant', 'adlakhag', 'ravi.gautam.94617', 'sks_.foodie', 'bake_with_khyati', 'm_u_k_e_s_h_2.o', 'ms__sipun', 'southassamroadlines', '_gopika_unnikrishnan_', 'shiveta.sharma', '__dead_guru_15__', 'status_videos_official_18', 'sravanthda1', 'rani.sauda', 'uz_baker15', 'reemachila', 'kolkatafoodtrek', 'guilymagnoduarte', 'eatwithrina', 'sanchita_24', 'riseoven', 'kiankhurana', 'readersmania', 'udayraj_55', 'jollyricha', 'black_boy._o9', 'pushpendra_rastogi', 'abhilashmishra01', 'sprakhar93', 'shwetaarao', 'foodymonkcafe', 'chefs_infusion', 'ig_.dev_', 'ritikkaushik3354', 'dynamic_smith_4', 'aakash.101020', 'roposotrending', 'vipinsingh_7777', 'sakshikishorejoshi', 'shipmyparcels', 'veglegacy', 'ayankhan1112_', 'anu_mannu_lovers', 'bishnu_priyanka', 'gurjarkajal16', '_._hema._', 'pahari.prince.7773', 'sevenspoons.in', 'hungrymunch', 'neee408', 'fresh_cookbyneelanjana', 'sakshi_joshi_4565', 'rajboy255', 'singhal1596', 'foodie_crush26', 'trupalcolthearts', 'somnath.dewangan.1612', 'shrivastavasurbhi111', 'liya_vlogs', 'fuddiet', 'nely_kolarovva', 'our_moft', 'sohilk851', 'sofia_94i', 'ishansharawat', 'discoverwithpinks_96', 'ishikaaesthetics', 'rshreetajane', 'vikram.ahuja.5030', 'nashto.in', 'wrapdindia', 'aaloogobhi', 'raj_rathod_8585', 'peehu143_', 'abhishekraj8525', 'manjeet_mehra_2361', '__.mehaaakkkk14.__', 'ratan_6456', 'm_soni_sharma_', 'official_rupes_h_01', 'scooby.pinkpanther', 'akula86vinodh', 'jasneet.kaur.1703', 'shiva.jimaratha', 'my_momentszing', 'iswaria.akhil', 'xairmureng', 'chikeyskollam', 'thekebabcafe', 'jarydendres', 'sanober_fatima_25', 'harrysingh5541', 'neelammohanani', 'ashishddavidd', 'edwinlorance3', 'bakaasaurus', 'itssubendu', 'varshamalik23', 'plus_secure', 'sugandhachaudhary.20', 'sheenajain9', 'moullupsious', 'esskaygram', 'hassanrj.najmul', 'neeraj_chopra_fan5', 'am_pm_waffle', 'sowrabhjadhav', 'indiasimplify', 'f_foodgarden', 'aaru.chaudhari__', 'dailydose63', 'gotohoshiai', 'spoonsofsizzle', 'shivanichowdhary5', 'ravidjrockers', 'ktv__71', 'walkfoodtalk', 'mushtaq3048', 'enolailapur', 'saba7640', 'my_heaven_logo007', 'anishajuneja1', 'northeast_pickle_store_pvt_ltd', 'darbar_shree_kuldeep_banna', 'dairy_engineer', 'ruchi.jainn', 'ishuhans_22', 'anewinstinct', 'dibba_._', '_2horh', 'bibleverseswithjorie', 'greendalepackaging', 'khoda.6776', '_silent_obsrver', 'virat_mishra_15', 'flavoursbyshy', 'eatburngrow', 'pretty.queen804', 'dip_tunes', 'foody_me0021', 'deepus.cooking.food', 'bewafa__jatti', 'soham__grafix', 'ilyasshabana.h', 'shrivastavaujjwal', 'prajnapoojari55', 'vedantgarud3', 'cookking68', 'digitalshinemedia', 'anamshuaib1711', 'nathshaonli', 'abhishekverma9418.__king', '08jitesh', 'rajnihareshpatel', 'mahesh.tarafdar00143', 'kanishkaa.kumarr', 'krishna_088k', 'bannasahabsaha7828695590', 'ayush_singh_officials', 'julesqiaohuvw', 'roshniforever1993', 'fatama_tuj_johora7135', 'ilaf__ansari', 'incredibleindianheroes', '_its_.raven', 'shaaanziii', 'a_woman_growing_wings', 'denim_collections3', 'harsh_vardhan4484', 'kingcarter352', 'pallavigulati7', 'iamcalledraza', 'sikha_898', 'bhookanya', 'nehas_ins', 'purimadhulika', 'trupti.attal', 'harikesh9713', '_queen_of_beauty01', 'vishnupriya6720', 'kukiinlondon', 'zaxy_x0naah', 'cookingforyou24', 'equifolio_', 'gntrekx', 'official__samiyaa', 'mygococo', 'endisless', 'samiksha3216', 'alyaminfoods', 'fashion_with_afifa', 'lets_eat_mumbai', 'prarthna_bhatia', 'chandan_yadav_1334', 'mariamraza15', 'shettybhaii', 'itsdrchauhan4u', 'ashu_yt__officel', '_.love.__soul', 'vishal05v', '_lovey_boy_arul_65', 'the_foodie_girl_27', 'hruthvikx', 'danish._7866', 'sarakhan75440', 'thefoodcanvas_', 'surabhi_goodbuy', '_arwaa.10', 'altaluneternity', 'serialcookersofficial', 'awais_raja_7676', 'mr_vibodh__00_', 'sethi_h430', 'sopankandalkar2021', 'zaka_jafri', 'waqarqazi39', 'vati_86', 'mr.sunil_1122', 'tgb_cafe_vastral_', 'soumen92ch', 'pole7344', '_suhaani_sharma', 'mr_jodha001', 'salaha_aktar', 'amirakhan.5', 'sharmin.rahmann', 'shimuaktherr', 'rupshiaki', 'gipshee', 'aktherrupshi', 'vaishali.gala.100', 'arifulislam_03', 'bubbllecore', 'khansana06', 'pk_love_food', 'naveen_saras', 'chef_shubh_2806', 'royalblue06', 'kaur_simran_023', 'cravingplacess', 'raydakhan.5', 'gilly_2', 'shannuu05', 'ayeshaaa_077', 'mr_jaan_official_07', 'blacklove026', 'foodies_yeah', 'jerusheeyyy_dawat', 'adarsh_x20', 'offical_boy_naresh_143', '1234567_tiku', 'restrothelady', 'viraajpanchal', 'cyrutba23u', 'barshha_', 'style_spring_roll', 'deepkia_sen', 'rajeshvari.94', 'junir.sk', 'science_0_nator', 'yogesh_boss_420', 'isha.rakheja.nischal', 'shantha9005', 'arjittlovers', 'habea112', 'navpadmart', 'rajvir_singh_janda', 'suraj_boss000', 'beradebadrita', 'rohit_singh_rk72', 'swadpergram', 'royalclothingbysk', 'shahid_2497', 'just_anukriti', 'fuguoutofwater', 'goofygeminigirl', 'lapinozpizaprahladnagar', 'preetiijha', '083_joaovictorr', 'lavishkafernandes45', 'mandeepkalra88', 'mr_chikko_da__', 'malvika2', 'dream_holiday_amd', 'street_food_ak', 'arpitpriyadarshan1704', 'sanuboss_', '_foodiee_couple_', 'krishhhh79', 'marinasaha', 'scrunchy41', 'pushpaj.minj', 'kutriyarsneha', 'maddula.dhanalakshmi', 'anikakalha', 'zakaria.tanveer', 'faruuzi_foodies', 'saloni889058', 'sasta_foodiee', 'lsdin', 'suyashsurana', 'daringpk12', 'honma.kayoutk', 'ap_ple8043', 'kabirx2001', 'souvik__g', 'crunchchilli', 'pune.mumbainightout', 'deepak_mindfreak', 'disha_sharma24', 'pretty_queen_1436', 'palak_sharma279', '_freaky_food', 'noorstarsfan53', 'rajeev_neela', 'satheesh_vc', 'vikas.vij.961', 'thefoodose', 'akash.g_n', '_immani___', 'tanishta19', 'vi_kash8006', 'kirti_nanhe', 'dabger95', 'daal_tadka01', 'fooooodie__11', 'ibrahim.bey.47', 'balamani300', 'barbie_official27', 'vimudha_2108', 'hayat__249', 'sohna108', 'ajay1479yadav', 'smavi.rana', 'kishansonicrpfarmystudant', 'pawan.w.7030237758', 'mithaas03', 'sweetu78667', 'srikrishna.tripathi', 'shafichelsea', '___simplemanof_action27', 'namakkal_foodi_tn_88', 'priyanka_virendra', 'delish_delight_', 'apurvak058', 'folklore_communications', 'junaid_smarty_008', 'marcmendonca23', 'un_happily_happy', 'its_anairabritto', 'ikhsanhidayatttt', 'akilking315', 'dinakarreddy315', 'rottenblueberr13s', '_treat_n_travel_', 'khemka.abhishek', 'manjeet348', 'danshah007', 'kashmirs_pride', 's__d__p_006', 'im._king__avinash_', '___aakashdeep', 'paddy2122', 'dance_beat_prasun', 'sindhidryfruits', 'macarronandme', 'saif_rocky_bhai_55', 'rajgor__hassu', 'guptanikhiln', 'royal_roy_134', 'nikhil.dhawan11', '__pandu__rowdy_143', 'kya.coolhaihum', 'baijun_upadhyay', 'paandaan.organic', '__surajraut__s.r_555_', 'iamswastik04', 'divyaakhannaa', 'dheeran_moorthi_', 'shiftblr', 'i_m_sindhu__11', 'harshitasharma021', 'mohammed_saif_ul_haqibrahim', 'devrajyadav878426', 'bigbullgopalraje', 'namheepark', 'trippyjunction', 'smilingtauseef', 'dhruv9693', 'shilsrevenge', 'avaljuneja', 'mr_amjid_official', 'kavit6454', 'sachinaashita', 'vaishnavipatil7946', 'prayagraj.social', 'suhailgupta1972', 'swatikulkarni2112', 'martina.joe', 'fiftyshadesofdrool', 'hr_tera_aala_', 'sumitbagga82', 'i__am_ishwari', 'surabhipalwankar', 'joy66_48', 'madhu00722', 'hsrgks', 'ojenlife', 'priyanshchandak2']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "final_followers_list = []\n",
    "\n",
    "followers_window = driver.find_element_by_class_name(\"isgrP\")\n",
    "while True:\n",
    "    driver.execute_script(\n",
    "        'arguments[0].scrollTop = arguments[0].scrollTop + arguments[0].offsetHeight;',followers_window)\n",
    "    time.sleep(3)\n",
    "    followers_list = driver.find_elements_by_class_name(\"_0imsa\")\n",
    "    if len(followers_list) >= 500:\n",
    "        for i in range(500):\n",
    "            final_followers_list.append(followers_list[i].get_attribute(\"innerHTML\"))\n",
    "        break\n",
    "print(final_followers_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_followers_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> first 500 followers of ‘sodelhi’ </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we start fetching usernames for so delhi we need to close the followers window of foodtalkindia\n",
    "\n",
    "cross_button = driver.find_element_by_xpath('//div[@class = \"_1XyCr \"]/div/div/div/button/div')\n",
    "cross_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will again locate the search bar text box and then send value to the particular box\n",
    "\n",
    "searchbutton = driver.find_element_by_class_name(\"XTCLo\")\n",
    "searchbutton.send_keys(\"sodelhi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after that we will click the first page that appear after we have searched for the value\n",
    "\n",
    "sodelhi_button = driver.find_element_by_class_name(\"-qQT3\")\n",
    "sodelhi_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we will locate the follower button by inspecting and then we ll be clicking over the particulaer element\n",
    "\n",
    "followers_button = driver.find_element_by_xpath('//ul[@class = \"k9GMp \"]/li[2]/a')\n",
    "followers_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will do same as we have done in above case\n",
    "# i.e\n",
    "\n",
    "# We will take an empty final list in which we will appened the 500 usernames \n",
    "# also we will scroll until the followername list is more than or equal to 500\n",
    "\n",
    "# firstlty we will locate followers window element\n",
    "# start an infinite loop\n",
    "# Scroll on followers window ,not on main window \n",
    "# after each scroll \n",
    "# we will take followers list in every iteration of the scroll then updation it in next iteration \n",
    "# by the new height followers\n",
    "# Once it reaches >= 500 we will break the infinite loop\n",
    "\n",
    "# Lastly we will run over the followers list again and out of the list that must be around 500 usernames\n",
    "# we will run a loop for 500 iteration and take first 500 usernames into final list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rewatitaneja', 'dmiraki_events', '_ananyajaiswalll_', 'wtfashimaa', 'ayush_bansal18', 'ruchi__bindal', 'saurav15_official', 'lokeshgahlot09', 'influencers_agency2', 'nicolenadream', 'ravi_sonil', 'meghaa4_', 'aesthetical_expressions', '_btwitssahil__044', 'msteve2006', 'geeta.sharma.7374', 'suchaehwa_misul_', 'maha_lakshmi_k_m', 'anmolrikhraj', 'iamdeeptisharma', 'itsniruhere', 'ruliker.s', 'acashprasad', 'nikhitha4364', 'syed_shahid_786123', 'official_yadav_nee2', 'qazi_sirajuddin', '_ankush_d', 'thereal.unique_.goddess', 'pria_jaiswal', 'thekashifsyd', 'mysteriousgirl02021', '_rishabhsarkar', 'debnath.chandan.yy21', 'trishamogulothu', 'gauravdawar54', 'igaman__jain', 'mayankabhishek_', 'shubham.khatri__sk', 'layylaa66', 'puffsncakes', 'shlok.nangia', 'mr_tulsiram_07_', 'avaaaa.khan', 'saifalammohammed', 'fotografie_in_de', 'woahhhhphia', 'sahityapaigwar', 'bishtmeghaa', 'kasisiva9', 'k.i.s.s.burgers', 'hgjnvbffj', 'rajanarora747', 'indianspartans', 'tanvi_markan22', 'healthrio', 'singh__pratibha_', 'rikwidpik', '_moinpatel', 'nirmala_dasan_', '_zaidkhan786', 'dev_kulshrestha', 'mvrwaii', 'heythere4532', 'mehakkhanda', 'hemant6404', '04_shivangi_09', 'ananyawns', 'yadavnitish295', 'jessica.lwn', 'sophiascalora', 'itz_me_1107_', 'ishafatima3599', 'legendsneverdiemotivation', 'khatey_raho', '_rohann_singh', 'khushi26k', 'mahi_2089_', 'shruti.sharma.23', 'bhoomikkaaa_', 'nickhiltyagi', 'disshaurya', 'inara_017', 'abhaas.goyal', 'ahirbhudhanya_yog', 'aka_lazybuoy', 'ayush4aa', 'shubhamgarg_1811', '16_shrey', 'dilipgdk_01', 'karishmagautam__', 'banjara2108', 'harshiita3', 'ramshreerasoi', 'medha_s_singh', 'oyesahilsharma', 'drsimrann', 'smriti_sarroya_bareja', 'msharma_0028', 'through_the__looking__glass', 'sidhaksaini', '_.neyhhaa_', '_preeeetiiii_', 'arushified', 'amishamoh7', 'rutuja_nyayadhish', 'sachin.sen01', 'sahilaro8', 'brinda_solanki', 'silent_screm', 'riddhisaid_1', 'muditgarg20', '06_ra_shi', '_pragya_gupta___', 'arshiyakhan5610', 'nishhhitt', 'krishnaa_vasudevan', 'pandeychhaya', 'mughal_cuisine_foods', 'bhumi0670', 'delhiite_girl_hk', 'miss_perfect_physio', 'itz__niraj__roy', 'kalmesh_j', 'aniways_anil', 'itssmebhavya', 'bad_boy_mukesh143', 'vaibhavgaur87', 'vikas_664', 'neerajguggal05', 'allaboutp.s', 'bharat_vasi_93', '_shubhi_maurya2303', 'ranjansharma_23', 'aayushisingh015', 'wonder_soull_', 'patil__king__4215', 'itsme.shiv_', 'vj_vishakajain', 'aric.luthra', 'ekta_bengani', 'beliveerrrr', 'aman___sharma007', 'taaannnuuuu', 'desidiaries_delhi', 'mr.rishabhjain', '_addu_bhai_1.6', 'shinjinijain', 'rajatbhallaofficial', 'gyaanbykamar', 'parth._jain', 'deepanshusharma_', 'ashishkakoria', 'thelaborious11', 'mannifateh1', 'weirdo_._ridhzz', 'notniharika', 'gunning_guneet22', 'moses.james99', 'aaryography1', 'meri.delhi', 'beingshadab_being_shalini_27', '__.vara._', 'harsh.rajput29', 'atishay3d', 'nancybehal09', 't.b111222', 'shootoutpage83_kadir', 'eden.kaku', 'nishi_shoots_udaipur_', 'sudaa_pushkar', 'tanya_gupta507', 'abhishek.221b', 'frontospech', 'shuchinn_', '_._navyaaa_._', 'alankriti_agrawal', 'padum.kumar.56', 'iamaribanaeem', 'sama.4223', 'd.mdevika', 'deeptijain.06', 'himanshu4274', 'kadir_ahmed_1010', 'dr.tushar_saruk', 'n_khosla', 'komuu4758', 'disha_gupta9', 'aroraoh9', 'hemant.mathur', '__.serah_', 'meenas_spicebasket', 'chilly_swiss_rathore', 'shikhayadavdelhi', 'igpc111', 'lovikanarula', 'dhankanirohit', 'atishay_24', 'achoudhary205', 'soberdelhite', 'tushar_.rajput98', 'tanishaguliani_30', '_dharwalsons_', 'seejjjaaall', 'shrikratiarts', 'foodssup', 'vaibhav0234', 'bholi_chatori', 'niema.ism', 'iamniteshhh', 'aditi_igupta', 'rajkot_food', 'khannadeem.12', 'fozy_aa_', 'vissh1717', 'tales_ordinarygirl5', '___melodyofflowers__', 'amitsharma0549', 'u1er_d', 'atri.shweta610', 'royal_jatt_389', 'vanshika.__rawat', 'hi_okay_by', 'gappuloveable', 'varun__tiwari', 'deekshachoudhary12', 'hemurawat10', 'ogohokgkgk', 'brijchaudhary2', 'roya_l_72', 'gulshanrajz', 'iamsudhalohia', 'singh_aryan_842', 'karanbaghel36', 'g._____47', 'bay.kahni', 'dshkhjr', 'nau.shad_i4u', 'sherri.kolade.writes', 'boxer292929', 'aletotherescue', 'preetkang2019', 'anytime__fitness__chris', 'madhving', 'explorewithshivaay', 'saqiba_jalil', 'kanes2300', 'sahib_sawhney', 'jasminelykissas', 'simerkharbanda', 'kanishka.midha', 'midnight_cherryblossoms', 'nikhil_soni94', 'sukhda14', 'imzoyak894', 'shireenqureshi30', 'princee0009', 'rohankumar334', '_riyan_saikia', 'kartik_dhadda', 'navneet.chhabra', 'ce_9793', 'nidhish_jain16', 'reddy_harshitha_98', 'the.podicompany', 'anupampande_', 'sh4shankshekhar_', 'deepshikhasharma03', 'neha.berry', 'harlaksh_09', 'foodwithtingers', 'goswami67675', 'vrindagupta1615', 'bhumi_arora_02', 'amevainfra', 'i_am_lucifer_name', 'mojo_jojo3899', 'starlazylosser_04', 'riiiiiida', 'phalguni.shr', 'iamnaijo', 'mayank5559', 'abstractnoun', 'gowthrm', 'zippppyyyy', 'rastogihardik', 'iam.sahilarora', 'ramandeep002120', 'alacartcreations', 'lover2cricket', 'aparna_vashisth', 'bhaktijain0721', 'priyasingh_16_', 'paramjeetlimousine_vintagecars', 'handcrafted.by.arunima', 'adityaboral_03_', '_.ak_.a_.sh_', 'rwitix', 'sunnyjain9191', 'itsnahaaleooo', 'tripura.in', 'itz_honey10', 'azra_sidd', 'ayeeshahnie', 'roodra_a', 'ias_paradise', '_jay.raghav_', 'shambhavi__chauhan', 'shekher_a.s', '3__sif', 'sksofid', '_mahira.khan.0786', 'rajbirkaur_03', 'sohil_2.10', 'riddhichaudhary15', 'southassamroadlines', 'black.lover.0786', '_anytime______________________', 'sipsapeat', 'rohityadav.08', '_mahii_v', '_thenovember_girl', 'mayurimorade_16', 'natashakhurana', '_.ten11._', 'aniket_lakhe', 'karishma_676', 'karan_202145', '_thelifeofmewati_', 'wondersoulsakshi', '_deepanshusahu', 'doorbas_kitchen', 'kasshish_sehgal', 'the_sweatbreak_', 'foodvloggerbishwa', 'ankitsoren1', 'japna9422', 'saloni_pavitrakar', 'ashmalhotra666', 'shweta_bagri_1701', 'panjwani_harleen.kaur', 'radhika.26dec', 'neerurajpal2005', 'vs_2811_', 'piyushbhardwaj._', 'anish_chaudhari', 'krayah41', '_sonaliofficial_', 'md.sanul.12914', 'itsapvtt', 'ak701g', '26san_deep', 'soniya_shekhawat', 'pramod0421', 'trisha.singh29', 'life_with_jimsy', '_vrajbhagat_', '05jha', 'nehagogia', 'the.bohemianpalace', 'henza.ali11', 'adimran277', 'rock_pawan01', 'shreya_aggarwal2050', 'use_ramenn', 'khaana_shanaa_love', 'nrityaakanksha', 'ashishpatel2210', 'pooja_masoom', 'baliramavasare', '_its_pikachu_here', 'anandpatel6222', 'abhishake_singh_negi', 'tanmayata.n', 'a_sky_in', 'lovelyxo413', '_littlepickle_', 'muskaanarora._', 'iqnoor.s', '__shreyaa._', 'rakshi_300rns', 'mohdhaneef.haneef.75491', 'ashish___rana', 'haveabite_rohini', 'sparkling_lite_', 'gayathri_sampath', 'dominic_edward_photography', 'official__mahakal____', 'sandeepsmadan', 'ombeerchhawari', 'amrita_paswan_92', 'narges.shirazi1399', 'smita.chatterjee510', 'shahjinali45', 'sex_man_me', 'navya_tanwar', 'its_yoora_here', 'ashni_a', 'amanmalik9200', 'anishask6', 'the_.dexter', 'sakshisheel', 'yashpanchalx', '_ch.anchal', 'meeragupta0910', 'blissfulbites.bykavisha', 'daman.s.03', '_chahat_hans', 'nobi_____46', 'sakshik2405', 'happytimesbegun_', 'rheaa_pillai', 'raghav_baweja_', 'mr_mrs_118', 'akkixyadav', 'huffelpuffel15', 'sonam_singh179', 'rupali_mishra_1', 'panfilov_s', 'raj_ee____v', 'yashdua31', '_byar7', 'monaaggarwal71', 'smartin77_', 'daminibakhshi', 'pratyaksha_singh__', 'sevenspoons.in', 'anammirza5', 'sehgalneha_', 'tanya.4.9', 'amazonian_warrior_girl', 'laddushark', 'ashishpatale', 'deepaksaini00', 'harshil_chaturvedi', 'ashugoel0001', 'omgnish', 'i.s.h.i.k.a_chaturvedi', 'deepannshu_', 'damascenonaaiara', 'shubham_gupta159', 'raunikrajput', 'ckp.vt_', '_rohit_arora', 'grover.leenaa', 'babitaaryal23', 'india__bloggers', 'james__9x', 'kuldeep.saroj1', 'ayushmansingh143', 'the.pavan.m', 'shrutiikalra01', 'sh.iv1531', 'bobby__rajawat', 'kashafmirza96', 'kaurjass1818', 'shreyaa_aroraa', 'palak_dube', 'rohesh_army_bro', 'hastey2019', 'zuhare5012', 'a_n_j_u_a_r_u_l', 'santoshghyar', 'mr__mystical_____dimples', 'ashhwanipatiyal_hairstylist', 'khushii.kansal_', 'aditi.9091', '_ruler_rajput_', 'jayanti_gautam', 'vaishnav1097', 'arunlove55k', 'harshu_x1', 'divi__9', 'shipra_jain', 'gvishakha', 'still._hungry', 'sheet_al54', 'sharmaji.0.1', 'sherlockkaur', 'i_am_eswarraj', 'parikshitnevarekar', 'rahul.fitlife', 'kashishpreet_singh', 'perti_sharma_77', 'its_me_ansh__', 'sushma_malhotra00', 'soul_track11', 'priaa.m', 'sonia.vohraa', 'mahalingam__', 'the_perfect_gemini', 'benmukherji', 'sanskriti.__.agarwal', 'pushpavi26', 'quite.buttoned.up', 'zoay706', 'ankur.chaudhary.148116', 'eatingaswego', 'retro5ile', 'megh.fouzdar']\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "final_followers_list = []\n",
    "\n",
    "followers_window = driver.find_element_by_class_name(\"isgrP\")\n",
    "while True:\n",
    "    driver.execute_script(\n",
    "        'arguments[0].scrollTop = arguments[0].scrollTop + arguments[0].offsetHeight;',followers_window)\n",
    "    time.sleep(3)\n",
    "    followers_list = driver.find_elements_by_class_name(\"_0imsa\")\n",
    "    if len(followers_list) >= 500:\n",
    "        for i in range(500):\n",
    "            final_followers_list.append(followers_list[i].get_attribute(\"innerHTML\"))\n",
    "        break\n",
    "print(final_followers_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_followers_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Task 2: </h2>\n",
    "all the followers of “foodtalkindia” that you are following but those who don’t follow you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we search for foodtalkindia we need to close the followers window of so delhi.\n",
    "\n",
    "cross_button = driver.find_element_by_xpath('//div[@class = \"_1XyCr \"]/div/div/div/button/div')\n",
    "cross_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will locate the search bar text box and then send value to the particular box\n",
    "\n",
    "searchbutton = driver.find_element_by_class_name(\"XTCLo\")\n",
    "searchbutton.send_keys(\"foodtalkindia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after that we will click the first page that appear after we have searched for the value\n",
    "\n",
    "foodtalkindia_button = driver.find_element_by_class_name(\"-qQT3\")\n",
    "foodtalkindia_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets now click on Followed by information provided after the About page info \n",
    "# that shows us the mutal follower between page and us\n",
    "# Then we will include some wait till the page sub page opens and presence of the see all followers buttons dont appear\n",
    "# once appear it will \n",
    "\n",
    "followedBy_button = driver.find_element_by_class_name(\"tc8A9\")\n",
    "followedBy_button.click()\n",
    "wait_thenlikebutton_check = wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"ZIAjV \")))\n",
    "SeeAllFollowers_button = driver.find_element_by_class_name(\"ZIAjV \")\n",
    "SeeAllFollowers_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will take an empty result list\n",
    "# first of all find the following or follow button web elements through which lately we will check \n",
    "# if string contains \"Following\" in it or not\n",
    "# we will get a count of the ones which we follow\n",
    "# then we will take the username of each one we follow in a temp list\n",
    "# open them one by one\n",
    "# go to their following list and check if our username appears at first or not \n",
    "# if not we will append them into our result list\n",
    "# else we will continue the iteration as if our username appears first that means they follow us back\n",
    "# and lastly we will get the driver back two times\n",
    "# and proceed with the next follower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_the_classic_kitchen_\n",
      "ritikkaushik3354\n",
      "southassamroadlines\n",
      "shipmyparcels\n",
      "foodymonkcafe\n",
      "bake_with_khyati\n"
     ]
    }
   ],
   "source": [
    "followername_ResultList = []\n",
    "following_button = driver.find_elements_by_class_name(\"sqdOP  \")\n",
    "followerName = driver.find_elements_by_class_name(\"_0imsa \")\n",
    "\n",
    "\n",
    "count = 0\n",
    "for i in following_button:\n",
    "    x = i.get_attribute(\"innerHTML\")\n",
    "    if x == \"Following\":\n",
    "        count = count + 1\n",
    "    else:\n",
    "        break\n",
    "\n",
    "tempusername = []\n",
    "for i in range(count):\n",
    "    tempusername.append(followerName[i].get_attribute(\"innerHTML\"))\n",
    "\n",
    "\n",
    "i = 0\n",
    "for i in range(count):\n",
    "    followerName = driver.find_elements_by_class_name(\"_0imsa \")\n",
    "    followerName[i].click()\n",
    "    following_button_and_wait = wait.until(EC.presence_of_element_located((By.XPATH, \"//ul[@class = 'k9GMp ']/li[3]/a\")))\n",
    "    following_button_and_wait.click()\n",
    "    followername_and_wait = wait.until(EC.presence_of_element_located((By.CLASS_NAME, \"_0imsa \")))\n",
    "    tempFirstfollower = followername_and_wait.get_attribute(\"innerHTML\")\n",
    "    if \"SAMPLE USERNAME\" == tempFirstfollower:\n",
    "        continue\n",
    "    followername_ResultList.append(tempusername[i])\n",
    "    \n",
    "    driver.back()\n",
    "    driver.back()\n",
    "\n",
    "for i in followername_ResultList:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>ASK 7</h2><br>\n",
    "<b><h4>Check the story of ‘coding.ninjas’. Consider the following Scenarios and print error messages accordingly -</b></h4>\n",
    "<b>1:</b>\n",
    "If You have already seen the story.<br>\n",
    "<b>2:</b>\n",
    "Or The user has no story.<br>\n",
    "<b>3:</b>\n",
    "Or View the story if not yet seen.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# before we search for coding.ninjas we need to close the followers window of foodtalkindia.\n",
    "\n",
    "cross_button = driver.find_element_by_xpath('//div[@class = \"_1XyCr \"]/div/div/div/button/div')\n",
    "cross_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will locate the search bar text box and then send value to the particular box\n",
    "\n",
    "searchbutton = driver.find_element_by_class_name(\"XTCLo\")\n",
    "searchbutton.send_keys(\"coding.ninjas\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# after that we will click the first page that appear after we have searched for the value\n",
    "\n",
    "CN_button = driver.find_element_by_class_name(\"-qQT3\")\n",
    "CN_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use try and except block\n",
    "# first we will try to locate the story button through xpath\n",
    "# chances are there may occur No such element Exception Reason would be \"No story is uploaded on this page\"\n",
    "# Then we will inspect again and get the height attribute value from a certain class and typecast into int \n",
    "# if height is 168 story is not seen so we will click on profile icon to see the story\n",
    "# if height is 167 story is seen so we will print that story is already seen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Watching the story right now\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    story_button = driver.find_element_by_xpath(\"//div[contains(@class,'h5uC0')]\")\n",
    "    h=int(driver.find_element_by_class_name(\"CfWVH\").get_attribute('height'))\n",
    "    if h == 168:\n",
    "        story_button.click()\n",
    "        print(\"Watching the story right now\")\n",
    "    else:\n",
    "        print(\"Story on this page is already seen by you\")\n",
    "\n",
    "except:\n",
    "    print(\"No story is uploaded on this page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
